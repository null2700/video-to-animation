# Video to Gesture Animation

## Project Overview
This project converts raw video input into gesture-based animations by extracting key frames, recognizing gestures with computer vision, and animating 3D models to produce realistic gesture sequences.
## Visual Explanation

### Final Output  
<img width="1816" height="630" alt="Final Output" src="https://github.com/user-attachments/assets/d93293cc-1c3d-466c-8c06-9d6830825a74" />

### Data Generation  
<img width="1808" height="631" alt="Data Generation" src="https://github.com/user-attachments/assets/f7ccdf0f-8fbc-4023-930d-7f81f3388671" />

### Backend Working  
<img width="969" height="640" alt="Backend Working" src="https://github.com/user-attachments/assets/ce94d96f-9cc3-4e5a-92d2-6d2ffc1edf36" />

### Code for Backend  
<img width="1391" height="349" alt="Backend Code" src="https://github.com/user-attachments/assets/760ca094-dc16-45e0-8e54-3a35f6d8a40f" />
## Key Features
- Extracts and preprocesses video frames
- Performs gesture recognition using advanced algorithms
- Maps gestures to 3D skeleton models for animation
- Produces smooth, lifelike animations
- Supports export and real-time visualization

## How It Works
1. Input video is processed to extract meaningful frames.
2. Gestures are identified on a frame-by-frame basis.
3. Gesture data controls 3D model animations.
4. Animated output can be viewed or exported.



## Future Work
- Utilize **Generative AI** to enhance gesture animation realism and diversity.
- Leverage **Large Language Models (LLMs)** for semantic understanding and gesture prediction based on context.
- Apply **Agentic AI** for pipeline automation and model improvement.
- Expand datasets with synthetic gestures using GANs.
- Develop interactive AI-powered tools for custom gesture animations.

## Getting Started
1. Clone the repository  
