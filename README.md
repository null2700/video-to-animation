# Video to Gesture Animation

## Project Overview
This project converts raw video input into gesture-based animations by extracting key frames, recognizing gestures with computer vision, and animating 3D models to produce realistic gesture sequences.

## Visual Explanation

### Final Output
<img width="1808" height="631" alt="Final Output" src="https://github.com/user-attachments/assets/4dfaafc8-0ed4-4ddd-8dbf-6517b7f16d82" />

### Data Generation
<img width="969" height="640" alt="Data Generation" src="https://github.com/user-attachments/assets/e7fe5fde-0fb9-4a94-bb63-12820a391d5e" />

### Backend Working
<img width="1391" height="349" alt="Backend Working" src="https://github.com/user-attachments/assets/2f253b16-355c-4345-ab31-b7b17e1ceb4d" />

### Code for Backend
<img width="1816" height="630" alt="Code for Backend" src="https://github.com/user-attachments/assets/18703fb4-9596-45eb-9cce-fcfed26f2b38" />

## Key Features
- Extracts and preprocesses video frames
- Performs gesture recognition using advanced algorithms
- Maps gestures to 3D skeleton models for animation
- Produces smooth, lifelike animations
- Supports export and real-time visualization

## How It Works
1. Input video is processed to extract meaningful frames.
2. Gestures are identified on a frame-by-frame basis.
3. Gesture data controls 3D model animations.
4. Animated output can be viewed or exported.

## Future Work
- Utilize **Generative AI** to enhance gesture animation realism and diversity.
- Leverage **Large Language Models (LLMs)** for semantic understanding and gesture prediction based on context.
- Apply **Agentic AI** for pipeline automation and model improvement.
- Expand datasets with synthetic gestures using GANs.
- Develop interactive AI-powered tools for custom gesture animations.



